{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf12qzFM4csL",
        "outputId": "139c5ba6-41e3-4d18-8d9a-2477a7ee6dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.9587\n",
            "Epoch 1: loss improved from inf to 2.95865, saving model to weights-improvement-01-2.9587.hdf5\n",
            "1129/1129 [==============================] - 872s 770ms/step - loss: 2.9587\n",
            "Epoch 2/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.7595\n",
            "Epoch 2: loss improved from 2.95865 to 2.75948, saving model to weights-improvement-02-2.7595.hdf5\n",
            "1129/1129 [==============================] - 871s 771ms/step - loss: 2.7595\n",
            "Epoch 3/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.6585\n",
            "Epoch 3: loss improved from 2.75948 to 2.65850, saving model to weights-improvement-03-2.6585.hdf5\n",
            "1129/1129 [==============================] - 862s 764ms/step - loss: 2.6585\n",
            "Epoch 4/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.5828\n",
            "Epoch 4: loss improved from 2.65850 to 2.58280, saving model to weights-improvement-04-2.5828.hdf5\n",
            "1129/1129 [==============================] - 873s 773ms/step - loss: 2.5828\n",
            "Epoch 5/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.5213\n",
            "Epoch 5: loss improved from 2.58280 to 2.52132, saving model to weights-improvement-05-2.5213.hdf5\n",
            "1129/1129 [==============================] - 834s 739ms/step - loss: 2.5213\n",
            "Epoch 6/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.4650\n",
            "Epoch 6: loss improved from 2.52132 to 2.46500, saving model to weights-improvement-06-2.4650.hdf5\n",
            "1129/1129 [==============================] - 840s 744ms/step - loss: 2.4650\n",
            "Epoch 7/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.4127\n",
            "Epoch 7: loss improved from 2.46500 to 2.41266, saving model to weights-improvement-07-2.4127.hdf5\n",
            "1129/1129 [==============================] - 851s 754ms/step - loss: 2.4127\n",
            "Epoch 8/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.3621\n",
            "Epoch 8: loss improved from 2.41266 to 2.36206, saving model to weights-improvement-08-2.3621.hdf5\n",
            "1129/1129 [==============================] - 873s 773ms/step - loss: 2.3621\n",
            "Epoch 9/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.3175\n",
            "Epoch 9: loss improved from 2.36206 to 2.31753, saving model to weights-improvement-09-2.3175.hdf5\n",
            "1129/1129 [==============================] - 902s 799ms/step - loss: 2.3175\n",
            "Epoch 10/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.2748\n",
            "Epoch 10: loss improved from 2.31753 to 2.27479, saving model to weights-improvement-10-2.2748.hdf5\n",
            "1129/1129 [==============================] - 916s 811ms/step - loss: 2.2748\n",
            "Epoch 11/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.2343\n",
            "Epoch 11: loss improved from 2.27479 to 2.23429, saving model to weights-improvement-11-2.2343.hdf5\n",
            "1129/1129 [==============================] - 892s 790ms/step - loss: 2.2343\n",
            "Epoch 12/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.1966\n",
            "Epoch 12: loss improved from 2.23429 to 2.19665, saving model to weights-improvement-12-2.1966.hdf5\n",
            "1129/1129 [==============================] - 868s 769ms/step - loss: 2.1966\n",
            "Epoch 13/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.1575\n",
            "Epoch 13: loss improved from 2.19665 to 2.15747, saving model to weights-improvement-13-2.1575.hdf5\n",
            "1129/1129 [==============================] - 902s 799ms/step - loss: 2.1575\n",
            "Epoch 14/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.1211\n",
            "Epoch 14: loss improved from 2.15747 to 2.12113, saving model to weights-improvement-14-2.1211.hdf5\n",
            "1129/1129 [==============================] - 920s 815ms/step - loss: 2.1211\n",
            "Epoch 15/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.0883\n",
            "Epoch 15: loss improved from 2.12113 to 2.08834, saving model to weights-improvement-15-2.0883.hdf5\n",
            "1129/1129 [==============================] - 931s 824ms/step - loss: 2.0883\n",
            "Epoch 16/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.0585\n",
            "Epoch 16: loss improved from 2.08834 to 2.05853, saving model to weights-improvement-16-2.0585.hdf5\n",
            "1129/1129 [==============================] - 922s 816ms/step - loss: 2.0585\n",
            "Epoch 17/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 2.0288\n",
            "Epoch 17: loss improved from 2.05853 to 2.02881, saving model to weights-improvement-17-2.0288.hdf5\n",
            "1129/1129 [==============================] - 904s 801ms/step - loss: 2.0288\n",
            "Epoch 18/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 1.9998\n",
            "Epoch 18: loss improved from 2.02881 to 1.99976, saving model to weights-improvement-18-1.9998.hdf5\n",
            "1129/1129 [==============================] - 888s 787ms/step - loss: 1.9998\n",
            "Epoch 19/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 1.9746\n",
            "Epoch 19: loss improved from 1.99976 to 1.97460, saving model to weights-improvement-19-1.9746.hdf5\n",
            "1129/1129 [==============================] - 874s 774ms/step - loss: 1.9746\n",
            "Epoch 20/20\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 1.9478\n",
            "Epoch 20: loss improved from 1.97460 to 1.94776, saving model to weights-improvement-20-1.9478.hdf5\n",
            "1129/1129 [==============================] - 888s 787ms/step - loss: 1.9478\n"
          ]
        }
      ],
      "source": [
        "##импорт необходимых библиотек\n",
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback\n",
        "#процедура для пред обработки данных\n",
        "def preprocess():\n",
        "  filename = \"wonderland.txt\"\n",
        "  raw_text = open(filename).read()\n",
        "  raw_text = raw_text.lower()\n",
        "\n",
        "  chars = sorted(list(set(raw_text)))\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "  n_chars = len(raw_text)\n",
        "  n_vocab = len(chars)\n",
        "\n",
        "  seq_length = 100\n",
        "  dataX = []\n",
        "  dataY = []\n",
        "  for i in range(0, n_chars - seq_length, 1):\n",
        "      seq_in = raw_text[i:i + seq_length]\n",
        "      seq_out = raw_text[i + seq_length]\n",
        "      dataX.append([char_to_int[char] for char in seq_in])\n",
        "      dataY.append(char_to_int[seq_out])\n",
        "  n_patterns = len(dataX)\n",
        "\n",
        "  X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "  X = X / float(n_vocab)\n",
        "  y = np_utils.to_categorical(dataY)\n",
        "\n",
        "  return X, y\n",
        "#создаём процедуру для генерации модель с входными параметрами X и y\n",
        "def create_model(X, y):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(y.shape[1], activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)\n",
        "\n",
        "  return history\n",
        "\n",
        "X, y = preprocess()\n",
        "history = create_model(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO0GnfgdYNYr",
        "outputId": "4a831cc4-b604-4c1d-dbc6-aca474c2efed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Characters:  144519\n",
            "Total Vocab:  45\n",
            "Total Patterns:  144419\n",
            "Seed:\n",
            "\" ng in coils.'\n",
            "\n",
            "'what was that like?' said alice.\n",
            "\n",
            "'well, i can't show it you myself,' the mock turtl \"\n",
            "e seilied. \n",
            "'no tou dene to toe to tea it 'soe part woing ' said the manch hare.\n",
            "\n",
            "'i can tou daei to tee that tha samd thing!' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the soon,' said the cate pi a sore of teete \n",
            "ant rheer in the sase  and the was how a ait. and the was how aooing the shilg bade to the thitel  she was eoong to the white tabdi tare the was now a little boo aro the tabli, \n",
            "'ieve poe to hete ' said the manch hare.\n",
            "\n",
            "'i can tou die ' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the saad ' aaied the manch hare.\n",
            "\n",
            "'i can tou daei to tee that that ' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the saad ' aaied the manch hare.\n",
            "\n",
            "'i can tou daei to tee that that ' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the saad ' aaied the manch hare.\n",
            "\n",
            "'i can tou daei to tee that that ' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the saad ' aaied the manch hare.\n",
            "\n",
            "'i can tou daei to tee that that ' said the manch hare.\n",
            "\n",
            "'i cane tou dave io the saad ' aaied the manch hare.\n",
            "\n",
            "'i can tou daei to tee that t\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#импорт необходимых библиотек\n",
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback\n",
        "#загружаем текст ASCII для книги в память и преобразовать все символы в нижний регистр, чтобы уменьшить словарный запас, который должна выучить сеть.\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "#создаём сопоставление уникальных символов с целыми числами и обратное сопоставление\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "#суммируем загруженные данные\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "#подготавливаем набор данных ввода к выходным парам, закодированным как целые числа\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "#изменяем форму X, чтобы он был [выборки, временные шаги, функции]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "#нормализуем\n",
        "X = X / float(n_vocab)\n",
        "y = np_utils.to_categorical(dataY)\n",
        "#создаём LSTM модель\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "#загружаем вес сети\n",
        "filename = \"weights-improvement-20-1.9478.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "#выбираем рандомный seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "#генерируем characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
